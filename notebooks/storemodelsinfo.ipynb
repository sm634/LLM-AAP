{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import SingleStoreDB\n",
    "from langchain_community.vectorstores.singlestoredb import SingleStoreDB\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "from sqlalchemy import *\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from chromadb.api.types import EmbeddingFunction\n",
    "from langchain_community.document_loaders import JSONLoader, CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=CSVLoader(\"FoundationModels-Data-b.csv\")\n",
    "models_info= loader.load()\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\ufeff\")\n",
    "# Split text into chunks\n",
    "models_rows = text_splitter.split_documents(models_info)\n",
    "\n",
    "models_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_json = ['\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Code Llama\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"70B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"CodeLlama - 70B\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"Meta\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Decoder-only\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 100000,\\\\n  \\\\\"Price\\\\\": \\\\\"Free\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"Python\\\\\", \\\\\"C++\\\\\", \\\\\"Java\\\\\", \\\\\"PHP\\\\\", \\\\\"Typescript (Javascript)\\\\\", \\\\\"C#\\\\\", \\\\\"Bash\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Instruction-tuned\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Code and code-related data\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Code generation\\\\\", \\\\\"natural language about code\\\\\", \\\\\"debugging\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Low latency, real-time code completion, long inputs\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Provide the model with code or natural language prompts\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Code and natural language about code\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": true,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Community license as Llama 2\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Deepseek Coder\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"33B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"deepseek-coder-33b-instruct\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"deepseek-ai\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Decoder-only\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 16000,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"Python\\\\\", \\\\\"English\\\\\", \\\\\"Chinese\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Instruction-tuned\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Project-level code corpus\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Code generation\\\\\", \\\\\"Code completion\\\\\", \\\\\"Code infilling\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Project-level code completion and infilling\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Provide the model with code or natural language prompts\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Code and natural language\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": false,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Other (see the LICENSE-MODEL for more details)\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Falcon-180B\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"180B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"tiiuae/falcon-180B\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"TII\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Decoder-only\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 2048,\\\\n  \\\\\"Price\\\\\": \\\\\"Unknown\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\", \\\\\"German\\\\\", \\\\\"Spanish\\\\\", \\\\\"French\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Raw, pretrained model\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"RefinedWeb enhanced with curated corpora\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Research\\\\\", \\\\\"Finetuning\\\\\", \\\\\"Specialization\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Inference\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Consider finetuning for specific usecases\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text generation\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": false,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Publicly accessible\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Falcon-180B TII License and Acceptable Use Policy\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Falcon-40B\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"40B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"tiiuae/falcon-40b\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"TII\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Decoder-only\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 2048,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\", \\\\\"German\\\\\", \\\\\"Spanish\\\\\", \\\\\"French\\\\\", \\\\\"Italian\\\\\", \\\\\"Portuguese\\\\\", \\\\\"Polish\\\\\", \\\\\"Dutch\\\\\", \\\\\"Romanian\\\\\", \\\\\"Czech\\\\\", \\\\\"Swedish\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Raw, pretrained model\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"1,000B tokens of RefinedWeb enhanced with curated corpora\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Research\\\\\", \\\\\"Finetuning\\\\\", \\\\\"Specialization\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Inference\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Consider finetuning for specific usecases\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text generation\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": false,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Apache 2.0 license\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"FLAN-T5 XL\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"2.85B params\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"google/flan-t5-xl\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"Hugging Face\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Transformers\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 512,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\", \\\\\"Spanish\\\\\", \\\\\"Japanese\\\\\", \\\\\"Persian\\\\\", \\\\\"Hindi\\\\\", \\\\\"French\\\\\", \\\\\"Chinese\\\\\", \\\\\"Bengali\\\\\", \\\\\"Gujarati\\\\\", \\\\\"German\\\\\", \\\\\"Telugu\\\\\", \\\\\"Italian\\\\\", \\\\\"Arabic\\\\\", \\\\\"Polish\\\\\", \\\\\"Tamil\\\\\", \\\\\"Marathi\\\\\", \\\\\"Malayalam\\\\\", \\\\\"Oriya\\\\\", \\\\\"Panjabi\\\\\", \\\\\"Portuguese\\\\\", \\\\\"Urdu\\\\\", \\\\\"Galician\\\\\", \\\\\"Hebrew\\\\\", \\\\\"Korean\\\\\", \\\\\"Catalan\\\\\", \\\\\"Thai\\\\\", \\\\\"Dutch\\\\\", \\\\\"Indonesian\\\\\", \\\\\"Vietnamese\\\\\", \\\\\"Bulgarian\\\\\", \\\\\"Filipino\\\\\", \\\\\"Central Khmer\\\\\", \\\\\"Lao\\\\\", \\\\\"Turkish\\\\\", \\\\\"Russian\\\\\", \\\\\"Croatian\\\\\", \\\\\"Swedish\\\\\", \\\\\"Yoruba\\\\\", \\\\\"Kurdish\\\\\", \\\\\"Burmese\\\\\", \\\\\"Malay\\\\\", \\\\\"Czech\\\\\", \\\\\"Finnish\\\\\", \\\\\"Somali\\\\\", \\\\\"Tagalog\\\\\", \\\\\"Swahili\\\\\", \\\\\"Sinhala\\\\\", \\\\\"Kannada\\\\\", \\\\\"Zhuang\\\\\", \\\\\"Igbo\\\\\", \\\\\"Xhosa\\\\\", \\\\\"Romanian\\\\\", \\\\\"Haitian\\\\\", \\\\\"Estonian\\\\\", \\\\\"Slovak\\\\\", \\\\\"Lithuanian\\\\\", \\\\\"Greek\\\\\", \\\\\"Nepali\\\\\", \\\\\"Assamese\\\\\", \\\\\"Norwegian\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Instruction-tuned\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"A mixture of tasks including those in the table below (from the original paper, figure 2)\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Research on zero-shot NLP tasks and in-context few-shot learning\\\\\", \\\\\"NLP tasks such as reasoning, and question answering\\\\\", \\\\\"Advancing fairness and safety research\\\\\", \\\\\"Understanding limitations of current large language models\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Provide the model with appropriate prompts\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": true,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Apache 2.0\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"FLAN-T5 XXL\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"11.3B params\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"google/flan-t5-xxl\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"Google\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Transformer\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 512,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\", \\\\\"German\\\\\", \\\\\"French\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Instruction-tuned\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"A mixture of tasks including reasoning, question answering, and more\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Research on language models\\\\\", \\\\\"Zero-shot NLP tasks\\\\\", \\\\\"In-context few-shot learning\\\\\", \\\\\"Advancing fairness and safety research\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Language model generation\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": false,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Apache 2.0\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Flan-UL2\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"20B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"google/flan-ul2\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"Google\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Encoder-decoder\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 2048,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\", \\\\\"French\\\\\", \\\\\"German\\\\\", \\\\\"Spanish\\\\\", \\\\\"Italian\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Flan Prompting\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"C4, Flan datasets\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Text generation\\\\\", \\\\\"Question answering\\\\\", \\\\\"Translation\\\\\", \\\\\"Summarization\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Few-shot in-context learning\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Provide the model with instruction-based prompts\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": true,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Apache-2.0\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Jais-13b-chat\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"13B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"jais-13b-chat\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"core42\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Decoder-only\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 2048,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"Arabic\\\\\", \\\\\"English\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Finetuned\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Arabic and English prompt-response pairs\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Conversational AI\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Bilingual conversations\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Follow the specific prompt format\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text responses\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": false,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Apache 2.0\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"ELYZA-japanese-Llama-2-7b-instruct\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"6.27B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"ELYZA-japanese-Llama-2-7b-instruct\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"Meta\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Decoder-only\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 256,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"Japanese\\\\\", \\\\\"English\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Instruction-tuned\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Text generation\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Provide the model with text prompts\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": false,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Llama 2 Community License\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Llama-2\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"13B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"meta-llama/Llama-2-13b-hf\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"Meta\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Transformer\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 4096,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF)\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"A new mix of publicly available online data\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Assistant-like chat\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Follow specific formatting, including INST and > tags, BOS and EOS tokens, and whitespaces and breaklines\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": false,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Custom commercial license available\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"llama2-dpo-v7\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"13.2B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"mncai/llama2-13b-dpo-v7\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"MindsAndCompany\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Decoder-only\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 2048,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\", \\\\\"Korean\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Instruction-tuned and Differential Privacy Optimized\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Text generation\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Provide the model with text prompts\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": false,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Llama 2 license\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Mistral-7B-Instruct-v0.2\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"7B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"Mistral-7B-Instruct-v0.2\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"Mistral AI\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Transformers\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 32000,\\\\n  \\\\\"Price\\\\\": 2.09,\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Finetuned conversational inference\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Text generation inference\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Text generation\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Inference Endpoints\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Surround your prompt with [INST] and [/]\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": true,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Apache-2.0\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Mixtral-8x7B-Instruct-v0.1\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"8x7B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"mistralai/Mixtral-8x7B-Instruct-v0.1\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"Mistral AI\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Sparse Mixture of Experts\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 2048,\\\\n  \\\\\"Price\\\\\": 3.74,\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\", \\\\\"French\\\\\", \\\\\"German\\\\\", \\\\\"Spanish\\\\\", \\\\\"Italian\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Instruction-tuned\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Text generation\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Use the specific instruction format\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": true,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Apache-2.0\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Mixtral-8x7B\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"8B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"TheBloke/Mixtral-8x7B-v0.1-GPTQ\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"Hugging Face\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Transformer\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 4096,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\", \\\\\"French\\\\\", \\\\\"German\\\\\", \\\\\"Italian\\\\\", \\\\\"Spanish\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"GPTQ\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Text generation\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"4-bit precision\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"No specific template\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": true,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Apache-2.0\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Multilingual-E5-large\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"24 layers, embedding size 1024\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"intfloat/multilingual-e5-large\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"Hugging Face\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Transformer\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 512,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\n    \\\\\"Afrikaans\\\\\",\\\\n    \\\\\"Albanian\\\\\",\\\\n    \\\\\"Amharic\\\\\",\\\\n    \\\\\"Arabic\\\\\",\\\\n    \\\\\"Armenian\\\\\",\\\\n    \\\\\"Assamese\\\\\",\\\\n    \\\\\"Azerbaijani\\\\\",\\\\n    \\\\\"Bashkir\\\\\",\\\\n    \\\\\"Basque\\\\\",\\\\n    \\\\\"Belarusian\\\\\",\\\\n    \\\\\"Bengali\\\\\",\\\\n    \\\\\"Bosnian\\\\\",\\\\n    \\\\\"Bulgarian\\\\\",\\\\n    \\\\\"Burmese\\\\\",\\\\n    \\\\\"Catalan\\\\\",\\\\n    \\\\\"Central Khmer\\\\\",\\\\n    \\\\\"Chinese\\\\\",\\\\n    \\\\\"Croatian\\\\\",\\\\n    \\\\\"Czech\\\\\",\\\\n    \\\\\"Danish\\\\\",\\\\n    \\\\\"Dutch\\\\\",\\\\n    \\\\\"English\\\\\",\\\\n    \\\\\"Esperanto\\\\\",\\\\n    \\\\\"Estonian\\\\\",\\\\n    \\\\\"Finnish\\\\\",\\\\n    \\\\\"French\\\\\",\\\\n    \\\\\"Galician\\\\\",\\\\n    \\\\\"Georgian\\\\\",\\\\n    \\\\\"German\\\\\",\\\\n    \\\\\"Greek\\\\\",\\\\n    \\\\\"Gujarati\\\\\",\\\\n    \\\\\"Hausa\\\\\",\\\\n    \\\\\"Hebrew\\\\\",\\\\n    \\\\\"Hindi\\\\\",\\\\n    \\\\\"Hungarian\\\\\",\\\\n    \\\\\"Icelandic\\\\\",\\\\n    \\\\\"Indonesian\\\\\",\\\\n    \\\\\"Interlingua\\\\\",\\\\n    \\\\\"Irish\\\\\",\\\\n    \\\\\"Italian\\\\\",\\\\n    \\\\\"Japanese\\\\\",\\\\n    \\\\\"Javanese\\\\\",\\\\n    \\\\\"Kannada\\\\\",\\\\n    \\\\\"Kazakh\\\\\",\\\\n    \\\\\"Khmer\\\\\",\\\\n    \\\\\"Korean\\\\\",\\\\n    \\\\\"Kurdish\\\\\",\\\\n    \\\\\"Kyrgyz\\\\\",\\\\n    \\\\\"Lao\\\\\",\\\\n    \\\\\"Latin\\\\\",\\\\n    \\\\\"Latvian\\\\\",\\\\n    \\\\\"Lithuanian\\\\\",\\\\n    \\\\\"Malagasy\\\\\",\\\\n    \\\\\"Malay\\\\\",\\\\n    \\\\\"Malayalam\\\\\",\\\\n    \\\\\"Marathi\\\\\",\\\\n    \\\\\"Moldavian\\\\\",\\\\n    \\\\\"Mongolian\\\\\",\\\\n    \\\\\"Nepali\\\\\",\\\\n    \\\\\"Norwegian\\\\\",\\\\n    \\\\\"Persian\\\\\",\\\\n    \\\\\"Polish\\\\\",\\\\n    \\\\\"Portuguese\\\\\",\\\\n    \\\\\"Romanian\\\\\",\\\\n    \\\\\"Russian\\\\\",\\\\n    \\\\\"Sanskrit\\\\\",\\\\n    \\\\\"Serbian\\\\\",\\\\n    \\\\\"Sindhi\\\\\",\\\\n    \\\\\"Sinhala\\\\\",\\\\n    \\\\\"Slovak\\\\\",\\\\n    \\\\\"Slovenian\\\\\",\\\\n    \\\\\"Somali\\\\\",\\\\n    \\\\\"Spanish\\\\\",\\\\n    \\\\\"Swahili\\\\\",\\\\n    \\\\\"Swedish\\\\\",\\\\n    \\\\\"Tajik\\\\\",\\\\n    \\\\\"Tamil\\\\\",\\\\n    \\\\\"Telugu\\\\\",\\\\n    \\\\\"Thai\\\\\",\\\\n    \\\\\"Tibetan\\\\\",\\\\n    \\\\\"Turkish\\\\\",\\\\n    \\\\\"Ukrainian\\\\\",\\\\n    \\\\\"Urdu\\\\\",\\\\n    \\\\\"Uzbek\\\\\",\\\\n    \\\\\"Vietnamese\\\\\",\\\\n    \\\\\"Welsh\\\\\",\\\\n    \\\\\"Yiddish\\\\\"\\\\n  ],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Contrastive pre-training with weak supervision, supervised fine-tuning\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Filtered mC4 (title, page content), 400M CC News (title, news content), NLLB translation pairs, Wikipedia (hierarchical section title, passage), Filtered Reddit (comment, response), S2ORC (title, abstract) and citation pairs, Stackexchange (question, answer), xP3 (input prompt, response)\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\n    \\\\\"Feature extraction\\\\\",\\\\n    \\\\\"Sentence similarity\\\\\",\\\\n    \\\\\"Inference endpoints\\\\\"\\\\n  ],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Multilingual understanding\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Use \\'query:\\' and \\'passage:\\' prefixes for input texts\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Sentence embeddings\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": true,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"MIT\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Prometheus\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"13B\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"Prometheus-13b-v1.0\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"kaist-ai\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Transformers\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 2048,\\\\n  \\\\\"Price\\\\\": 0.12,\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Fine-tuned on 100K feedback within the Feedback Collection\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Text2Text Generation\\\\\", \\\\\"Inference Endpoints\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Language model using Llama-2-Chat as a base model and fine-tuned for evaluating long-form responses\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Follow the specific prompt format required by the model\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Detailed feedback and a score between 1 and 5\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": true,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Apache 2.0\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Granite 13 Billion Model (granite.13b)\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"13 Billion\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"Granite13B\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"IBM\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Decoder-only\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 8000,\\\\n  \\\\\"Price\\\\\": 0.0,\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Supervised Fine-Tuning (SFT) and Contrastive Fine Tuning (CFT)\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"Internet, academic, code, legal, and finance data\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Question and answer\\\\\", \\\\\"Generation\\\\\", \\\\\"Extraction\\\\\", \\\\\"Summarization\\\\\", \\\\\"Classification\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Business use\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Follow the guidelines provided by IBM\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Text generation\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": true,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Worldwide\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Available only through IBM products and offerings. Contact IBM for licensing terms.\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Granite (13B) Instruct V2.0\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"13 Billion\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"granite.13b.v2.instruct\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"IBM\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Decoder-only\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 8192,\\\\n  \\\\\"Price\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Instruction-tuned\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"2.5T Tokens, MMLU (5-shot), granite.13b.2500b.chat\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"English based classification\\\\\", \\\\\"extraction\\\\\", \\\\\"summarization\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"The model benefits from flan-templated data in its alignment step and therefore should perform well with flan-style prompt templates.\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": true,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Available only through IBM products and offerings.\\\\\"\\\\n}\"',\n",
    " '\"{\\\\n  \\\\\"ModelName\\\\\": \\\\\"Granite Chat\\\\\",\\\\n  \\\\\"Size\\\\\": \\\\\"13 Billion\\\\\",\\\\n  \\\\\"ID\\\\\": \\\\\"granite-13b-chat-v2\\\\\",\\\\n  \\\\\"Provider\\\\\": \\\\\"IBM\\\\\",\\\\n  \\\\\"Architecture\\\\\": \\\\\"Decoder-only\\\\\",\\\\n  \\\\\"ContextLength\\\\\": 8000,\\\\n  \\\\\"Price\\\\\": \\\\\"Contact IBM for licensing terms\\\\\",\\\\n  \\\\\"Languages\\\\\": [\\\\\"English\\\\\"],\\\\n  \\\\\"TunningInformation\\\\\": \\\\\"Massive Multitask Language Understanding (MMLU) and Multi-Turn(MT) Bench benchmarks, novel alignment technique for LLMs using large-scale targeted alignment for a generalist LLM\\\\\",\\\\n  \\\\\"TrainingData\\\\\": \\\\\"2.5 Trillion Tokens, IBM\\'s curated pre-training dataset\\\\\",\\\\n  \\\\\"UsesSupported\\\\\": [\\\\\"Question and Answering (RAG)\\\\\", \\\\\"summarization\\\\\", \\\\\"generation\\\\\", \\\\\"extraction\\\\\", \\\\\"classification\\\\\"],\\\\n  \\\\\"OptimisedFor\\\\\": \\\\\"English-based closed-domain Question and Answering, longer responses preferred in RAG-like use cases\\\\\",\\\\n  \\\\\"PromptingAdvice\\\\\": \\\\\"Proper English text, no tagging or media, text only evaluation datasets\\\\\",\\\\n  \\\\\"Output\\\\\": \\\\\"English text\\\\\",\\\\n  \\\\\"PromptTuningAvailability\\\\\": false,\\\\n  \\\\\"RegionalAvailability\\\\\": \\\\\"Not specified\\\\\",\\\\n  \\\\\"License\\\\\": \\\\\"Available only through IBM products and offerings. Contact IBM for licensing terms.\\\\\"\\\\n}\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the pre-trained model you want to use\n",
    "modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "\n",
    "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
    "model_kwargs = {'device':'cpu'}\n",
    "\n",
    "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniLML6V2EmbeddingFunction(EmbeddingFunction):\n",
    "    MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    def __call__(self, texts):\n",
    "        return MiniLML6V2EmbeddingFunction.MODEL.encode(texts).tolist()\n",
    "emb_function = MiniLML6V2EmbeddingFunction()\n",
    "\n",
    "def get_text_embedding(texts: list[list[str]], \n",
    "                       batch: int = 1000) -> list[Any]:\n",
    "        \"\"\"\n",
    "        Get the embeddings from the text.\n",
    "\n",
    "        Args:\n",
    "            texts (list(str)): List of chucks of text.\n",
    "            batch (int): Batch size.\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch):\n",
    "            text_batch = texts[i:(i+batch)]\n",
    "            # Embeddings model\n",
    "            emb_batch = emb_function(text_batch)\n",
    "            embeddings.append(emb_batch)\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_url = \"singlestoredb://root:rootpasstest@localhost:3306\"\n",
    "engine = create_engine(connection_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"CREATE DATABASE IF NOT EXISTS \" +  \"TRIALS_DB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available databases:\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(singlestoredb.exceptions.OperationalError) 2003: Can't connect to MySQL server on '20.241.246.145' (timed out)\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/singlestoredb/mysql/connection.py:962\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 962\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:851\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[0;32m--> 851\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExceptionGroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_connection failed\u001b[39m\u001b[38;5;124m\"\u001b[39m, exceptions)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:836\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    835\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 836\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3293\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3272\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3273\u001b[0m \n\u001b[1;32m   3274\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3291\u001b[0m \n\u001b[1;32m   3292\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1269\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1269\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 716\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:169\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:167\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:902\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/create.py:645\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/default.py:616\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/singlestoredb/connection.py:1424\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(host, user, password, port, database, driver, pure_python, local_infile, charset, ssl_key, ssl_cert, ssl_ca, ssl_disabled, ssl_cipher, ssl_verify_cert, ssl_verify_identity, conv, credential_type, autocommit, results_type, buffered, results_format, program_name, conn_attrs, multi_statements, connect_timeout, nan_as_null, inf_as_null, encoding_errors, track_env)\u001b[0m\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmysql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/singlestoredb/mysql/connection.py:547\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_cipher, ssl_disabled, ssl_key, ssl_verify_cert, ssl_verify_identity, parse_json, invalid_values, pure_python, buffered, results_type, compress, named_pipe, passwd, db, driver, conn_attrs, multi_statements, nan_as_null, inf_as_null, encoding_errors, track_env)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/singlestoredb/mysql/connection.py:1030\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[38;5;28mprint\u001b[39m(exc\u001b[38;5;241m.\u001b[39mtraceback)\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m# If e is neither DatabaseError or IOError, It's a bug.\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# But raising AssertionError hides original error.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# So just reraise it.\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: 2003: Can't connect to MySQL server on '20.241.246.145' (timed out)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable databases:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m      3\u001b[0m     result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mexecute(text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHOW DATABASES\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3269\u001b[0m, in \u001b[0;36mEngine.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[1;32m   3247\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[1;32m   3248\u001b[0m \n\u001b[1;32m   3249\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3266\u001b[0m \n\u001b[1;32m   3267\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/base.py:147\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 147\u001b[0m         \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2431\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[0;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2430\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2433\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    147\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[1;32m    148\u001b[0m             err, dialect, engine\n\u001b[1;32m    149\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3293\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m   3272\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3273\u001b[0m \n\u001b[1;32m   3274\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3291\u001b[0m \n\u001b[1;32m   3292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m    445\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1269\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1266\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1269\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1272\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    714\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 716\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:169\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/impl.py:167\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[1;32m    391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:902\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/pool/base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/create.py:645\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    643\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sqlalchemy/engine/default.py:616\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/singlestoredb/connection.py:1424\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(host, user, password, port, database, driver, pure_python, local_infile, charset, ssl_key, ssl_cert, ssl_ca, ssl_disabled, ssl_cipher, ssl_verify_cert, ssl_verify_identity, conv, credential_type, autocommit, results_type, buffered, results_format, program_name, conn_attrs, multi_statements, connect_timeout, nan_as_null, inf_as_null, encoding_errors, track_env)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m driver \u001b[38;5;129;01mor\u001b[39;00m driver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmysql\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmysql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/singlestoredb/mysql/connection.py:547\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_cipher, ssl_disabled, ssl_key, ssl_verify_cert, ssl_verify_identity, parse_json, invalid_values, pure_python, buffered, results_type, compress, named_pipe, passwd, db, driver, conn_attrs, multi_statements, nan_as_null, inf_as_null, encoding_errors, track_env)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/singlestoredb/mysql/connection.py:1030\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[1;32m   1029\u001b[0m         \u001b[38;5;28mprint\u001b[39m(exc\u001b[38;5;241m.\u001b[39mtraceback)\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m# If e is neither DatabaseError or IOError, It's a bug.\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# But raising AssertionError hides original error.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# So just reraise it.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (singlestoredb.exceptions.OperationalError) 2003: Can't connect to MySQL server on '20.241.246.145' (timed out)\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "print(\"Available databases:\")\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SHOW DATABASES\"))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SINGLESTOREDB_URL\"] = \"root:rootpasstest@localhost:3306/TRIALS_DB\"\n",
    "categories_table = SingleStoreDB.from_texts(\n",
    "    texts=models_json,\n",
    "    embedding=embeddings,\n",
    "    table_name=\"MODELS\",\n",
    "    # content_field=\"category\",\n",
    "    # vector_field=\"vector\",\n",
    "    # metadata_field=\"metadata\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"USE TRIALS_DB;\"))\n",
    "    conn.execute(text(\"ALTER TABLE MODELS ADD COLUMN embeddings vector(384) AFTER vector;\"))\n",
    "    conn.execute(text(\"UPDATE MODELS SET embeddings = vector;\"))\n",
    "    conn.execute(text(\"ALTER TABLE MODELS DROP COLUMN vector\"))\n",
    "    conn.execute(text(\"ALTER TABLE MODELS CHANGE embeddings vector;\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for the models that best match the following description:\n",
      "{'original_request': '\\nA bank is receiving 100s of complaints a day.\\nThe data is in CSV format, stored in the AW3 cloud environment.\\nThey want to inject data into either an algorithm or an LLM, which can categorise the complaints into a list of 50 complaint types.\\nModel to categories the root cause issues.\\n',  'requirements': ['Language: English',    'Task(s): text classification',    'Function Calling:\\nThe user requirements do not imply a need for the production of structured outputs. The user wants to inject data into an algorithm or a large language model (LLM) to categorize complaints into a list of 50 complaint types. The output of this process would likely be a list or a set of categories, not a structured output like JSON or YAML.',    'Context Length: not a priority',    'Model Architecture: \\nEncoder-only',    'Industry: Banking'],  'key_words': 'Complaints\\nCSV\\nAW3\\nAlgorithm\\nLLM\\nCategorize\\nRoot Cause Issues\\n\\n\\n\\n\\n\\n'}  \n",
      "\n",
      "1: \"{\\n  \\\"ModelName\\\": \\\"Granite (13B) Instruct V2.0\\\",\\n  \\\"Size\\\": \\\"13 Billion\\\",\\n  \\\"ID\\\": \\\"granite.13b.v2.instruct\\\",\\n  \\\"Provider\\\": \\\"IBM\\\",\\n  \\\"Architecture\\\": \\\"Decoder-only\\\",\\n  \\\"ContextLength\\\": 8192,\\n  \\\"Price\\\": \\\"Not specified\\\",\\n  \\\"Languages\\\": [\\\"English\\\"],\\n  \\\"TunningInformation\\\": \\\"Instruction-tuned\\\",\\n  \\\"TrainingData\\\": \\\"2.5T Tokens, MMLU (5-shot), granite.13b.2500b.chat\\\",\\n  \\\"UsesSupported\\\": [\\\"English based classification\\\", \\\"extraction\\\", \\\"summarization\\\"],\\n  \\\"OptimisedFor\\\": \\\"Not specified\\\",\\n  \\\"PromptingAdvice\\\": \\\"The model benefits from flan-templated data in its alignment step and therefore should perform well with flan-style prompt templates.\\\",\\n  \\\"Output\\\": \\\"Not specified\\\",\\n  \\\"PromptTuningAvailability\\\": true,\\n  \\\"RegionalAvailability\\\": \\\"Not specified\\\",\\n  \\\"License\\\": \\\"Available only through IBM products and offerings.\\\"\\n}\"  \n",
      "\n",
      "Score: 0.591354250907898\n",
      "\n",
      "2: \"{\\n  \\\"ModelName\\\": \\\"Granite 13 Billion Model (granite.13b)\\\",\\n  \\\"Size\\\": \\\"13 Billion\\\",\\n  \\\"ID\\\": \\\"Granite13B\\\",\\n  \\\"Provider\\\": \\\"IBM\\\",\\n  \\\"Architecture\\\": \\\"Decoder-only\\\",\\n  \\\"ContextLength\\\": 8000,\\n  \\\"Price\\\": 0.0,\\n  \\\"Languages\\\": [\\\"English\\\"],\\n  \\\"TunningInformation\\\": \\\"Supervised Fine-Tuning (SFT) and Contrastive Fine Tuning (CFT)\\\",\\n  \\\"TrainingData\\\": \\\"Internet, academic, code, legal, and finance data\\\",\\n  \\\"UsesSupported\\\": [\\\"Question and answer\\\", \\\"Generation\\\", \\\"Extraction\\\", \\\"Summarization\\\", \\\"Classification\\\"],\\n  \\\"OptimisedFor\\\": \\\"Business use\\\",\\n  \\\"PromptingAdvice\\\": \\\"Follow the guidelines provided by IBM\\\",\\n  \\\"Output\\\": \\\"Text generation\\\",\\n  \\\"PromptTuningAvailability\\\": true,\\n  \\\"RegionalAvailability\\\": \\\"Worldwide\\\",\\n  \\\"License\\\": \\\"Available only through IBM products and offerings. Contact IBM for licensing terms.\\\"\\n}\"  \n",
      "\n",
      "Score: 0.5875870585441589\n",
      "\n",
      "3: \"{\\n  \\\"ModelName\\\": \\\"Prometheus\\\",\\n  \\\"Size\\\": \\\"13B\\\",\\n  \\\"ID\\\": \\\"Prometheus-13b-v1.0\\\",\\n  \\\"Provider\\\": \\\"kaist-ai\\\",\\n  \\\"Architecture\\\": \\\"Transformers\\\",\\n  \\\"ContextLength\\\": 2048,\\n  \\\"Price\\\": 0.12,\\n  \\\"Languages\\\": [\\\"English\\\"],\\n  \\\"TunningInformation\\\": \\\"Fine-tuned on 100K feedback within the Feedback Collection\\\",\\n  \\\"TrainingData\\\": \\\"Not specified\\\",\\n  \\\"UsesSupported\\\": [\\\"Text2Text Generation\\\", \\\"Inference Endpoints\\\"],\\n  \\\"OptimisedFor\\\": \\\"Language model using Llama-2-Chat as a base model and fine-tuned for evaluating long-form responses\\\",\\n  \\\"PromptingAdvice\\\": \\\"Follow the specific prompt format required by the model\\\",\\n  \\\"Output\\\": \\\"Detailed feedback and a score between 1 and 5\\\",\\n  \\\"PromptTuningAvailability\\\": true,\\n  \\\"RegionalAvailability\\\": \\\"Not specified\\\",\\n  \\\"License\\\": \\\"Apache 2.0\\\"\\n}\"  \n",
      "\n",
      "Score: 0.5865578055381775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "\n",
    "    searchstring = input('Please enter a search string: ')\n",
    "\n",
    "    print(f\"Searching for the models that best match the following description:\\n{searchstring} \\n\")\n",
    "\n",
    "    search_embedding = get_text_embedding(searchstring)\n",
    "\n",
    "    embedded_search = json.dumps(search_embedding.tolist()[0])\n",
    "\n",
    "    results = conn.execute(text(f\"SELECT content, DOT_PRODUCT(vector, '{embedded_search}':> vector(384)) AS score FROM MODELS ORDER BY score DESC LIMIT 3;\"))\n",
    "\n",
    "    for i, res in enumerate(results):\n",
    "        print(f'{i + 1}: {res.content}  \\n\\nScore: {res.score}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
